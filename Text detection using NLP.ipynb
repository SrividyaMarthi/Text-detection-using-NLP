{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import nltk.corpus\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "# import pymysql\n",
    "# import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[\n",
    "('KBA0001','Dragon 360 Network Edition: PowerMic and Audio Issues'),\n",
    "('KBA0002','Oracle: Oracle Hierarchy Issues'),\n",
    "('KBA0003','Epic OneChart Cupid: How to Create a STEMI Case'),\n",
    "('KBA0004','Epic HIM: Mark Duplicate Patient Charts for Merge'),\n",
    "('KBA0005','Epic oneChart: Schedulable Epic Resource Record Updates/Corrections'),\n",
    "('KBA0006','Hardware: Desktop Scanner Troubleshooting'),\n",
    "('KBA0007','Remote Access: Connecting Mobile Device to Citrix'),\n",
    "('KBA0008','Internet Explorer: Blocked Website'),\n",
    "('KBA0009','Oakwood HealthStream: Password Reset'),\n",
    "('KBA0010','Epic: Timeout Extension Request'),\n",
    "('KBA0011','Internet Explorer: Clearing Temp Files, Cookies, and Cache'),\n",
    "('KBA0012','Citrix: Missing Applications')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data[11][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.append('not')\n",
    "stopwords.append('access')\n",
    "stopwords.append('schedule')\n",
    "Lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(cdata):\n",
    "    cdata=cdata.replace('*','').replace('-',' ').replace('/',' ').replace(\"'\",' ')\n",
    "    punct_list=[str.lower().strip(string.punctuation) for str in cdata.split() if cdata not in stopwords]\n",
    "    lemma_list=[Lemmatizer.lemmatize(token) for token in punct_list if len(token)> 0]\n",
    "    cdata=' '.join(word for word in lemma_list)\n",
    "    return cdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_list=[training_data[i][0] for i in range(len(training_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list=[clean_data(training_data[i][1]) for i in range(len(training_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(ngram_range=(1,2),token_pattern=r'\\b\\w+\\b',min_df=1, vocabulary=None)),\n",
    "                      ('tfidf', TfidfTransformer(use_idf = True)),\n",
    "                      ('clf-svc',svm.SVC(kernel='linear', C = 1.0,probability=True))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_svm = text_clf_svm.fit(phrase_list,kb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(ngram_range=(1, 2),\n",
       "                                 token_pattern='\\\\b\\\\w+\\\\b')),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf-svc', SVC(kernel='linear', probability=True))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the query:missing applications\n"
     ]
    }
   ],
   "source": [
    "test_query = input(\"Enter the query:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['KBA0012'], dtype='<U7')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_svm.predict([clean_data(test_query)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
